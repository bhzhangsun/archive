{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python3使用教程\n",
    "\n",
    "python是非常主流的一门语言，常被用在网站，爬虫，科学计算等领域\n",
    "\n",
    "## python文件\n",
    "\n",
    "**标准注释：**\n",
    "```python\n",
    "#!/usr/bin/env python3 \n",
    "# -*- coding: utf-8 -*-\n",
    "```\n",
    "第一行作为通用环境的标准写法，保证在不同环境下正常执行，比如window和linux。第二行指定编码格式\n",
    "\n",
    "## python模块\n",
    "\n",
    "python模块的组织以文件或文件夹作为模块。**模块**作为一组函数与变量等符号的集合对外提供，来增加代码可复用性。模块的另一个作用是通过命名空间的方式，来组织不同功能的符号，以解决命名冲突。通常使用文件夹的方式称为包。\n",
    "\n",
    "包是以目录树的方式来组织模块的一种方式。内部包含子模块和子包\n",
    "\n",
    "```bash\n",
    "example           # 包\n",
    "  |-- __init__.py  # 标志这是一个包\n",
    "  |-- a.py\n",
    "  |-- b.py\n",
    "  |-- sub-lib     # 子包\n",
    "        |-- __init__.py\n",
    "        |-- c.py\n",
    "```\n",
    "\n",
    "__init__.py 一般内容。 文件也可以加这段代码，以作为可执行脚本执行。\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    print('作为可执行程序运行')\n",
    "else:\n",
    "    print('作为包初始化执行')\n",
    "```\n",
    "\n",
    "\n",
    "#### 模块的使用\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup # 引入bs4模块的BeautifulSoup符号\n",
    "import requests # 引入requests模块\n",
    "# from requests import * # 引入所有符号\n",
    "# import filename # 通过文件名引入\n",
    "requests.get('http://baidu.com') # 使用模块名来访问内部的共有变量\n",
    "```\n",
    "\n",
    "#### 模块的创建\n",
    "\n",
    "使用文件的方式来作为一个模块，或者报的方式来作为一个模块使用\n",
    "\n",
    "#### 模块的选择\n",
    "\n",
    "1. 当前目录\n",
    "2. PYTHONPATH环境变量\n",
    "3. python默认路径，比如/usr/local/lib/python\n",
    "\n",
    "#### 符号的查看\n",
    "\n",
    "> dir(module)  查看当前module模块内的符号\n",
    ">\n",
    "> globals()  查看当前位置能访问的全局变量\n",
    ">\n",
    "> locals()  查看当前位置能访问的局部变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3 \n",
    "# -*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup # 引入bs4模块的BeautifulSoup符号\n",
    "import requests # 引入requests模块\n",
    "resp = requests.get('https://baidu.com') # 使用模块名来访问内部的共有变量\n",
    "# print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python的使用\n",
    "\n",
    "#### 标识符\n",
    "\n",
    "1. 标识符有字母，数字，下划线组成。不易数字开头\n",
    "2. 以__开头标识私有变量，如 __foo\n",
    "3. 以__开头和结尾表示特殊变量，如 __init__\n",
    "\n",
    "#### 缩进与换行\n",
    "\n",
    "python使用缩进与换行来表示语句结束，或块范围。同一行有多个语句时才使用; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用python爬取小说\n",
    "\n",
    "使用requests爬取顶点小说https://www.ddxstxt8.com/\n",
    "\n",
    "1. 分析网站，发现有全部小说tab，收集了该网站的所有小说 /xiaoshuodaquan\n",
    "2. 小说列表是服务端直接渲染的html页面。\n",
    "3. 小说详情页有小说章节列表\n",
    "\n",
    "ps: 注意使用代理池以防止ip被封"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3 \n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "ua = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36'\n",
    "}\n",
    "\n",
    "def get_el_value(elements,  type='string', index = 0):\n",
    "    if index < len(elements):\n",
    "        if type == 'string':\n",
    "            return elements[index].string\n",
    "        elif type == 'text':\n",
    "            return elements[index].get_text()\n",
    "        else:\n",
    "            return elements[index][type]\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def url_concat(path, href):\n",
    "    prefix = re.match(r'^(https?://.*)/', path).group(1)\n",
    "    root = re.match(r'^(https?://.*?)/', path).group(1)\n",
    "    url = prefix\n",
    "    \n",
    "#     print('href', path, href, prefix, root)\n",
    "    if href.startswith('/'):\n",
    "        url = root + href\n",
    "    elif (href.startswith('./')):\n",
    "        url = prefix + href[1:]\n",
    "    else:\n",
    "        url = prefix + '/' + href\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_novel_list():\n",
    "    resp = requests.get('https://www.ddxstxt8.com/xiaoshuodaquan/', headers=ua)\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    data = soup.select('#main > div.novellist > ul > li > a')\n",
    "\n",
    "    novels = []\n",
    "    for item in data:\n",
    "        name = item.string\n",
    "        link = item['href']\n",
    "        novels.append({\n",
    "            'name': name,\n",
    "            'link': link\n",
    "        })\n",
    "    return novels\n",
    "\n",
    "# url = 'https://www.ddxstxt8.com/4_4891/'\n",
    "def get_novel(url):\n",
    "    chapters = []\n",
    "    resp = requests.get(url, headers=ua)\n",
    "    resp.encoding = \"gbk\"\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    \n",
    "    info = get_el_value(soup.select('#info > p:nth-child(2)'))\n",
    "    author = re.sub(r'^作.*者：', '', info)\n",
    "    novel_name = get_el_value(soup.select('#info > h1'))\n",
    "    desc = get_el_value(soup.select('#intro > p'))\n",
    "    img_path = get_el_value(soup.select('#fmimg > img'),'src')\n",
    "    img = url_concat(url, img_path)\n",
    "\n",
    "    data = soup.select('#list > dl > dd > a')[6:]\n",
    "    for item in data:\n",
    "        name = item.string\n",
    "        href = item['href']\n",
    "        chapters.append({\n",
    "            'chapter_name': name,\n",
    "            'link': url + href\n",
    "        })\n",
    "#     print(info, desc, name, img)\n",
    "    return {\n",
    "        'novel_name': novel_name,\n",
    "        'menu_link': url,\n",
    "        'image': img,\n",
    "        'author': author,\n",
    "        'desc': desc,\n",
    "        'chapters': chapters\n",
    "    }\n",
    "\n",
    "\n",
    "# url = 'https://www.ddxstxt8.com/1_1651/11057637.html'\n",
    "def get_article(url):\n",
    "    resp = requests.get(url, headers=ua)\n",
    "    resp.encoding = \"gbk\"\n",
    "    soup = BeautifulSoup(resp.text, 'html5lib')\n",
    "\n",
    "    name = get_el_value(soup.select('#wrapper > div.content_read > div > div.bookname > h1'))\n",
    "\n",
    "    text = get_el_value(soup.select('#content'), 'text')\n",
    "#     text = soup.select('#content')[0].get_text()\n",
    "    text = text.split('chaptererror()')[0]\n",
    "#     print(name, text)\n",
    "    return {\n",
    "        'article_name': name,\n",
    "        'article_text': text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels = get_novel_list()\n",
    "# print('novels:', novels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel = get_novel(novels[0]['link'])\n",
    "# print('novel:', novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_content = get_article('https://www.ddxstxt8.com/1_1651/11057637.html')\n",
    "# print(article_content['article_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加代理池防止IP被封\n",
    "\n",
    "ip代理池可以将我们的数据包分流发出，服务端通过http层的Reffer拿到的来源是经过一跳的。代理池甚至可以对这层进行处理，使之只有一个来源。以防止ip被封。\n",
    "\n",
    "使用商用ip代理池，更稳定，更方便。免费ip代理池基本没有可用ip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "def get_proxy():\n",
    "    def get_ips():\n",
    "        resp = requests.get('http://api.wandoudl.com/api/ip?app_key=0093c1a82bf9136e2222b88fdf78c6c2&pack=0&num=20&xy=1&type=2&lb=\\r\\n&mr=2&area_id=undefined')\n",
    "        body = resp.json()\n",
    "        if body['code'] != 200:\n",
    "            return []\n",
    "        return body['data']\n",
    "    proxys = get_ips()\n",
    "    if len(proxys) == 0:\n",
    "        print('重新请求...')\n",
    "        proxys = get_ips()\n",
    "    if len(proxys) > 0\n",
    "        proxy = proxys[random.randint(0, len(proxys)-1)]\n",
    "        if time.mktime(time.strptime(proxy['expire'], '') <= time.time()):\n",
    "#             proxys.remove('') # 移除失效ip\n",
    "            \n",
    "    print('resp', resp)\n",
    "get_proxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
